{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414a89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import spacy\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# change cwd to project root\n",
    "while os.path.split(os.getcwd())[-1] != \"project\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "NER, SENTIMENT_TOPIC = data.load()\n",
    "NER_ARRAY = data.NER_data_to_sentence_array(NER)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5803a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"en_core_web_trf\"  \n",
    "if importlib.util.find_spec(model_name) is None:\n",
    "    spacy.cli.download(model_name)\n",
    "    \n",
    "nlp_spacy = spacy.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bace5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting mismatch: T: you're I: you\n",
      "BIO mismatch: T: Louvre-ORG I: Louvre-FAC\n",
      "BIO mismatch: T: the-O I: the-WORK_OF_ART\n"
     ]
    }
   ],
   "source": [
    "spacy_bio_to_true_bio_mapping = {\n",
    "    \"PERSON\": \"PER\",\n",
    "    \"NORP\": \"MISC\",\n",
    "    \"FAC\": \"LOCATION\",\n",
    "    \"ORG\": \"ORG\",\n",
    "    \"GPE\": \"LOCATION\",\n",
    "    \"LOC\": \"LOCATION\",\n",
    "    \"PRODUCT\": \"MISC\",\n",
    "    \"EVENT\": \"MISC\",\n",
    "    \"WORK_OF_ART\": \"MISC\",\n",
    "    \"LAW\": \"MISC\",\n",
    "    \"LANGUAGE\": \"MISC\",\n",
    "    \"DATE\": \"MISC\",\n",
    "    \"TIME\": \"MISC\",\n",
    "    \"PERCENT\": \"MISC\",\n",
    "    \"MONEY\": \"MISC\",\n",
    "    \"QUANTITY\": \"MISC\",\n",
    "    \"ORDINAL\": \"MISC\",\n",
    "    \"CARDINAL\": \"MISC\",\n",
    "}\n",
    "\n",
    "correct_splits = 0\n",
    "correct_bio= 0\n",
    "\n",
    "total_splits = 0 \n",
    "total_bio = 0\n",
    "\n",
    "for sentence, metadata_array in NER_ARRAY:\n",
    "    spacy_doc = nlp_spacy(sentence)\n",
    "    total_splits += len(metadata_array)\n",
    "\n",
    "\n",
    "    spacy_doc_offset = 0\n",
    "    metadata_array_offset = 0\n",
    "    while True:\n",
    "        true_token = metadata_array[metadata_array_offset]\n",
    "        inferred_token = spacy_doc[spacy_doc_offset]\n",
    "\n",
    "        true_text = true_token[0]\n",
    "        inferred_text = inferred_token.text\n",
    "        if true_text != inferred_text:\n",
    "            print(f\"Splitting mismatch: T: {true_text} I: {inferred_text}\")\n",
    "            longest_token = max(true_text, inferred_text)\n",
    "            if longest_token == true_text:\n",
    "                # test data made the token longer, thus spacy must've split something\n",
    "                spacy_doc_offset += 1\n",
    "            elif longest_token == inferred_text:\n",
    "                # test data made the token longer, thus spacy must've split something\n",
    "                metadata_array_offset += 1\n",
    "        else:\n",
    "            correct_splits += 1\n",
    "        \n",
    "        spacy_doc_offset += 1\n",
    "        metadata_array_offset += 1\n",
    "\n",
    "        if spacy_doc_offset >= len(spacy_doc):\n",
    "            break\n",
    "        if metadata_array_offset >= len(metadata_array):\n",
    "            break\n",
    "\n",
    "        true_type = true_token[1].split(\"-\")[-1]\n",
    "        inferred_type = inferred_token.ent_type_ if inferred_token.ent_type_ else \"O\"\n",
    "\n",
    "        mapped_type = spacy_bio_to_true_bio_mapping.get(inferred_type)\n",
    "        total_bio += 1\n",
    "        if inferred_type == true_type or true_type == mapped_type:\n",
    "            correct_bio += 1\n",
    "        else:\n",
    "            print(f\"BIO mismatch: T: {true_text}-{true_type} I: {inferred_text}-{inferred_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324c5a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct splits: 0.9473684210526315\n",
      "Correct predictions: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Correct splits: {correct_splits / total_splits}\")\n",
    "print(f\"Correct predictions: {correct_bio / total_bio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
